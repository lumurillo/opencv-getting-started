{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Handling using Python3 and OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required modules\n",
    "These are the modules that we need to import throughout all the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Python, images are stored as numpy arrays\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from tempfile import gettempdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Capture\n",
    "### From file\n",
    "Let's start by learning how to capture from a file in disk.\n",
    "####  Error checking\n",
    "If the image does not exist or is not readable, then **None** will be returned instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_non_existing = cv2.imread('non-existing.jpg')\n",
    "if None == img_non_existing:\n",
    "    print(\"Unable to read image!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different color formats\n",
    "OpenCV allows us to load and decode the image in different color formats\n",
    "* cv2.IMREAD_COLOR : Loads a color image. Any transparency of image will be neglected. It is the default flag.\n",
    "* cv2.IMREAD_GRAYSCALE : Loads image in grayscale mode\n",
    "* cv2.IMREAD_UNCHANGED : Loads image as such including alpha channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "img_color = cv2.imread(str(Path('media') / 'lenna.png'), cv2.IMREAD_COLOR)\n",
    "print(img_color.shape)\n",
    "# Matplotlib needs BGR, so convert from RGB to BGR\n",
    "plt.imshow(cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.imread(str(Path('media') / 'barbara.jpg'), cv2.IMREAD_GRAYSCALE)\n",
    "print(img_gray.shape)\n",
    "plt.imshow(img_gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig = cv2.imread(str(Path('media') / 'diamond.png'), cv2.IMREAD_COLOR)\n",
    "print(img_orig.shape)\n",
    "plt.imshow(img_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From video\n",
    "Similar to images, OpenCV may read frames from a video file. To do so, a video capture object is created.\n",
    "#### Error checking\n",
    "The video capture provides a method to check if the video could be opened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_non_existing = cv2.VideoCapture('non-existing.mp4')\n",
    "if vid_non_existing.isOpened() == False:\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "# Release resources, even if it errored out\n",
    "vid_non_existing.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture frames\n",
    "Once the capture object is opened, we can retrieve frames from it until it is exhausted or an error occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_mp4 = cv2.VideoCapture(str(Path('media') / 'ball.mp4'))\n",
    "\n",
    "# Iterate until there are no more frames\n",
    "while(vid_mp4.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = vid_mp4.read()\n",
    "    if ret == False:\n",
    "        print(\"End of video\")\n",
    "        break\n",
    " \n",
    "    #cv2.imshow('Frame',frame)\n",
    "    #cv2.waitKey(25) # wait 25 ms between frames\n",
    "    plt.imshow(frame)\n",
    "    plt.show()\n",
    " \n",
    "vid_mp4.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video Properties\n",
    "You can query and set some properties on the video capture object such as capture size, format, etc... See [the documentation](https://docs.opencv.org/3.1.0/d8/dfe/classcv_1_1VideoCapture.html#a8c6d8c2d37505b5ca61ffd4bb54e9a7c)\n",
    "* CAP_PROP_POS_MSEC Current position of the video file in milliseconds.\n",
    "* CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next.\n",
    "* CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0 - start of the film, 1 - end of the film.\n",
    "* CAP_PROP_FRAME_WIDTH Width of the frames in the video stream.\n",
    "* CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream.\n",
    "* CAP_PROP_FPS Frame rate.\n",
    "* CAP_PROP_FOURCC 4-character code of codec.\n",
    "* CAP_PROP_FRAME_COUNT Number of frames in the video file.\n",
    "* CAP_PROP_FORMAT Format of the Mat objects returned by retrieve() .\n",
    "* CAP_PROP_MODE Backend-specific value indicating the current capture mode.\n",
    "* CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(str(Path('media') / 'ball.mp4'))\n",
    "\n",
    "width = vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "print (\"Queried image size is %dx%d\"%(width,height))\n",
    "\n",
    "ret, frame = vid.read()\n",
    "print(\"Real image size is %dx%d\"%(frame.shape[1], frame.shape[0]))\n",
    "\n",
    "# Videos cannot change their size from the capture object\n",
    "vid.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "vid.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "ret, frame = vid.read()\n",
    "print(\"Image size is still %dx%d\"%(frame.shape[1], frame.shape[0]))\n",
    " \n",
    "fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "print(\"FPS is %f\"%fps)\n",
    "\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Camera\n",
    "The same video capture object may be used to capture from a camera. If an integer is provided, it will be treated as the device number.\n",
    "```python\n",
    "cam = cv2.VideoCapture(deviceNumber)\n",
    "```\n",
    "\n",
    "#### Error checking\n",
    "Similar to the video case, a method is provided to query if the camera was able to open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(-1)\n",
    "if cam.isOpened() == False:\n",
    "    print(\"Error opening camera\")\n",
    "\n",
    "# Release resources, even if it errored out\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture frames\n",
    "Once the capture object is opened, frames are captured as in the video case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "cam = cv2.VideoCapture(0)\n",
    "count = 10\n",
    "\n",
    "# Iterate until there are no more frames (artifically limiting to 10 frames)\n",
    "while cam.isOpened() and count > 0:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cam.read()\n",
    "    if ret == False:\n",
    "        print(\"End of video\")\n",
    "        break;\n",
    " \n",
    "    plt.imshow(frame)\n",
    "    plt.show()\n",
    "    count -= 1\n",
    " \n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camera properties\n",
    "Cameras expose several properties such as capture size, format, etc... See [the documentation](https://docs.opencv.org/3.1.0/d8/dfe/classcv_1_1VideoCapture.html#a8c6d8c2d37505b5ca61ffd4bb54e9a7c)\n",
    "* CAP_PROP_POS_MSEC Current position of the video file in milliseconds.\n",
    "* CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next.\n",
    "* CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0 - start of the film, 1 - end of the film.\n",
    "* CAP_PROP_FRAME_WIDTH Width of the frames in the video stream.\n",
    "* CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream.\n",
    "* CAP_PROP_FPS Frame rate.\n",
    "* CAP_PROP_FOURCC 4-character code of codec.\n",
    "* CAP_PROP_FRAME_COUNT Number of frames in the video file.\n",
    "* CAP_PROP_FORMAT Format of the Mat objects returned by retrieve() .\n",
    "* CAP_PROP_MODE Backend-specific value indicating the current capture mode.\n",
    "* CAP_PROP_BRIGHTNESS Brightness of the image (only for cameras).\n",
    "* CAP_PROP_CONTRAST Contrast of the image (only for cameras).\n",
    "* CAP_PROP_SATURATION Saturation of the image (only for cameras).\n",
    "* CAP_PROP_HUE Hue of the image (only for cameras).\n",
    "* CAP_PROP_GAIN Gain of the image (only for cameras).\n",
    "* CAP_PROP_EXPOSURE Exposure (only for cameras).\n",
    "* CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB.\n",
    "* CAP_PROP_WHITE_BALANCE Currently unsupported\n",
    "* CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "vid = cv2.VideoCapture(device)\n",
    "\n",
    "width = vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "print (\"Queried image size is %dx%d\"%(width,height))\n",
    "\n",
    "ret, frame = vid.read()\n",
    "print(\"Real image size is %dx%d\"%(frame.shape[1], frame.shape[0]))\n",
    "\n",
    "# Cameras may change size\n",
    "vid.set(cv2.CAP_PROP_FRAME_WIDTH, 720)\n",
    "vid.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "ret, frame = vid.read()\n",
    "print(\"Image size is now %dx%d\"%(frame.shape[1], frame.shape[0]))\n",
    " \n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Display\n",
    "We have seen image display using matplotlib. That's because it's the way to display here in Jupyter. However OpenCV also has its own display mechanisms.\n",
    "\n",
    "### Using Matplotlib\n",
    "Besides the examples we've seen, here's some additional configuration.\n",
    "\n",
    "#### Remove axis\n",
    "Unless plotting data, axis are not really interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread (str(Path('media') / 'lenna.png'), cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subplots\n",
    "Sometimes it's interesting to plot several images in a single renderer for comparison purposes. Check some more [cool examples](https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread (str(Path('media') / 'lenna.png'), cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread (str(Path('media') / 'barbara.jpg'), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 1 row, 2 columns, currently at 1\n",
    "plt.subplot(121)\n",
    "plt.imshow (img1, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# 1 row, 2 columns, currently at 2\n",
    "plt.subplot(122)\n",
    "plt.imshow (img2, cmap='gray')\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenCV\n",
    "OpenCV has its own window system. Even though not as flexible, it may capture keyboard events. This wont render on this Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "cap = cv2.VideoCapture(device)\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        print (\"Error reading frame\")\n",
    "        break\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    if (cv2.waitKey(1) & 0xFF) == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Write\n",
    "Now we are going to learn how to save an image into a single file or a video.\n",
    "\n",
    "### Single image\n",
    "The most straightforward way to save an image file is to a single image. It may be a JPEG, PNG or many other formats. The format is chosen based on the extension of the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(str(Path('media') / 'barbara.jpg'))\n",
    "tmp_dir = gettempdir()\n",
    "cv2.imwrite(str(Path(tmp_dir) / 'barbara.png'), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although saving an image is similar in every format, each one may control different parameters. These parameters are optional.\n",
    "\n",
    "#### JPEG Images\n",
    "When saving as JPEG you may control the quality factor from 0 to 100. The default is 95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(str(Path('media') / 'barbara.jpg'))\n",
    "tmp_dir = gettempdir()\n",
    "cv2.imwrite(str(Path(tmp_dir) / 'barbara_lq.jpg'), img, [cv2.IMWRITE_JPEG_QUALITY, 1])\n",
    "img_lq = cv2.imread(str(Path(tmp_dir) / 'barbara_lq.jpg'))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(cv2.cvtColor(img_lq, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PNG Images\n",
    "When saving as PNG you may control the compression factor from 0 to 9 (higher the smaller size). Default is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(str(Path('media') / 'lenna.png'))\n",
    "tmp_dir = gettempdir()\n",
    "cv2.imwrite(str(Path(tmp_dir) / 'lenna_lq.png'), img, [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
    "img_lq = cv2.imread(str(Path(tmp_dir) / 'lenna_lq.png'))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(cv2.cvtColor(img_lq, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video File\n",
    "Similarly, images may be written to a video file. The encoding format is chosen using a fourcc. The full list may be seen on the [fourcc.org website](http://www.fourcc.org/codecs.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "cap = cv2.VideoCapture(device)\n",
    "\n",
    "fps = 10.0\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Sizes must match\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "\n",
    "count = 50\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'AVC1')\n",
    "\n",
    "tmp_dir = gettempdir()\n",
    "out = cv2.VideoWriter(str(Path(tmp_dir) / 'video.mp4'), fourcc, fps, (width,height))\n",
    "\n",
    "while cap.isOpened() and count > 0:\n",
    "    ret, frame = cap.read()\n",
    "    if ret==False:\n",
    "        print (\"Error reading frame\")\n",
    "        break\n",
    "\n",
    "    # write the flipped frame\n",
    "    out.write(frame)\n",
    "    count -= 1\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation\n",
    "Images are loaded as arrays.\n",
    "\n",
    "### Raw Indexing\n",
    "Let's explore how to access data manually\n",
    "\n",
    "#### Size of an image\n",
    "The `shape` method provides an easy way to get the dimensions of an image. In the following examples, *barbara* is a 512x512 RGB image, while *diamond* is a 245x225 RGBA image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbara = cv2.imread(str(Path('media') / 'barbara.jpg'), cv2.IMREAD_UNCHANGED)\n",
    "print(barbara.shape)\n",
    "\n",
    "diamond = cv2.imread(str(Path('media') / 'diamond.png'), cv2.IMREAD_UNCHANGED)\n",
    "print(diamond.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pixel access\n",
    "To access an individual pixel we index the image as a regular array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full RGB pixel\n",
    "print(barbara[100, 200])\n",
    "\n",
    "# Get the full RGB pixel, separated by components\n",
    "(R, G, B) = barbara[100,200]\n",
    "print(\"R: %d, G: %d, B: %d\"%(R, G, B))\n",
    "\n",
    "# Get each component independently\n",
    "R = barbara[100,200,0]\n",
    "G = barbara[100,200,1]\n",
    "B = barbara[100,200,2]\n",
    "print(\"R: %d, G: %d, B: %d\"%(R, G, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Range access\n",
    "Numpy allows you to index ranges. For example, the following syntax accesses ranges in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the red component from column 100 to 110 on row 200\n",
    "rng = barbara[100:110,200,0]\n",
    "print (rng)\n",
    "\n",
    "# Get the first 5 pixels of column 0\n",
    "rng = barbara[0,0:5]\n",
    "print (rng)\n",
    "\n",
    "# Get the blue components of the first row\n",
    "rng = barbara[:, 0, 2]\n",
    "print (rng)\n",
    "\n",
    "# Get the green channel of the image\n",
    "rng = barbara[:,:,1]\n",
    "print (rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stepping\n",
    "Numpy allows us to skip N items while accessing the array. For example:\n",
    "```python\n",
    "arr[a:b:c]\n",
    "```\n",
    "means, index from item `a` to item `b` in increments of `c` elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first 10 items of the first row, blue component\n",
    "orig = barbara[0:10,0,2]\n",
    "print (orig)\n",
    "\n",
    "# Read the first 10 items of the first row, blue component, in increments of 2 elements\n",
    "skip = barbara[0:10:2,0,2]\n",
    "print(skip)\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "# Read first row, red component\n",
    "orig = barbara[:,0,0]\n",
    "print (orig)\n",
    "\n",
    "# Read first row, red component, in increments of 2 elements\n",
    "skip = barbara[::2,0,0]\n",
    "print(skip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
